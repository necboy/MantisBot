// src/agents/openai-compat-runner.ts
// OpenAI å…¼å®¹çš„ Agent Runner å®ç°
// æ”¯æŒ OpenAIã€é€šä¹‰åƒé—®ã€Gemini ç­‰é Claude æ¨¡å‹

import { EventEmitter } from 'events';
import { getLLMClient } from './llm-client.js';
import { ToolRegistry } from './tools/registry.js';
import { getConfig } from '../config/loader.js';
import type { LLMMessage, FileAttachment, ToolInfo } from '../types.js';
import {
  type StreamChunk,
  type AgentResult,
  type AgentRunnerOptions,
  type ToolCallInfo,
  DANGEROUS_TOOLS,
  MAX_TOOL_RESULT_CHARS,
  TRUNCATION_SUFFIX,
} from './types.js';

/**
 * å·¥å…·ç»“æœæˆªæ–­
 */
function truncateToolResult(content: string): string {
  if (content.length <= MAX_TOOL_RESULT_CHARS) {
    return content;
  }

  const keepChars = MAX_TOOL_RESULT_CHARS - TRUNCATION_SUFFIX.length;

  // å°½é‡åœ¨æ¢è¡Œç¬¦å¤„æˆªæ–­
  let cutPoint = keepChars;
  const lastNewline = content.lastIndexOf('\n', keepChars);
  if (lastNewline > keepChars * 0.8) {
    cutPoint = lastNewline;
  }

  return content.slice(0, cutPoint) + TRUNCATION_SUFFIX;
}

/**
 * ä»å·¥å…·ç»“æœä¸­æ”¶é›†é™„ä»¶
 */
function collectAttachments(result: unknown, attachments: FileAttachment[]): void {
  if (result && typeof result === 'object') {
    let newItems: FileAttachment[] = [];

    // å¦‚æœç»“æœæœ‰ attachments å­—æ®µ
    if ('attachments' in result && Array.isArray(result.attachments)) {
      newItems = result.attachments as FileAttachment[];
    }
    // å¦‚æœç»“æœæœ¬èº«å°±æ˜¯ FileAttachment æ•°ç»„
    else if (Array.isArray(result) && result.length > 0 && 'url' in result[0]) {
      newItems = result as FileAttachment[];
    }
    // å¦‚æœç»“æœæ˜¯å•ä¸ª FileAttachment
    else if ('url' in result && 'name' in result && !Array.isArray(result)) {
      newItems = [result as FileAttachment];
    }

    // å»é‡
    const existingUrls = new Set(attachments.map(a => a.url));
    for (const item of newItems) {
      if (!existingUrls.has(item.url)) {
        attachments.push(item);
        existingUrls.add(item.url);
      }
    }
  }
}

// å®¡æ‰¹æ¨¡å¼ç±»å‹
type ApprovalMode = 'auto' | 'ask' | 'dangerous';

/**
 * OpenAI å…¼å®¹çš„ Agent Runner
 * æ”¯æŒæ‰€æœ‰é€šè¿‡ LLMClient è°ƒç”¨çš„é Claude æ¨¡å‹
 */
export class OpenAICompatRunner extends EventEmitter {
  private toolRegistry: ToolRegistry;
  private options: {
    model: string;
    systemPrompt: string;
    maxIterations: number;
    approvalMode: ApprovalMode;
  };
  private abortController: AbortController | null = null;

  constructor(
    toolRegistry: ToolRegistry,
    options: AgentRunnerOptions = {}
  ) {
    super();
    this.toolRegistry = toolRegistry;

    // å…¼å®¹æ—§çš„ autoApprove å‚æ•°ï¼Œè½¬æ¢ä¸º approvalMode
    let approvalMode: ApprovalMode = options.approvalMode || 'dangerous';
    if (options.autoApprove === true && !options.approvalMode) {
      approvalMode = 'auto';
    } else if (options.autoApprove === false && !options.approvalMode) {
      approvalMode = 'dangerous';
    }

    this.options = {
      model: options.model || '',
      systemPrompt: options.systemPrompt || '',
      maxIterations: options.maxIterations || 0, // 0 = æ— é™åˆ¶
      approvalMode,
    };

    // å¦‚æœæ²¡æœ‰æŒ‡å®šæ¨¡å‹ï¼Œä½¿ç”¨é…ç½®ä¸­çš„ç¬¬ä¸€ä¸ªæ¨¡å‹
    if (!this.options.model) {
      const config = getConfig();
      this.options.model = config.models[0]?.name || 'gpt-4';
    }

    console.log('[OpenAICompatRunner] Initialized with approvalMode:', approvalMode);
  }

  /**
   * åœæ­¢å½“å‰æ‰§è¡Œ
   */
  abort(): void {
    if (this.abortController) {
      console.log('[OpenAICompatRunner] Abort requested');
      this.abortController.abort();
    }
  }

  /**
   * æ£€æŸ¥å·¥å…·æ˜¯å¦ä¸ºå±é™©æ“ä½œ
   */
  private isDangerousTool(toolName: string): boolean {
    return DANGEROUS_TOOLS.has(toolName.toLowerCase());
  }

  /**
   * è·å–å½“å‰ä¼šè¯ IDï¼ˆOpenAI å…¼å®¹æ¨¡å¼ä¸æ”¯æŒä¼šè¯æ¢å¤ï¼‰
   */
  getSessionId(): null {
    return null;
  }

  /**
   * æµå¼è¿è¡Œ
   */
  async *streamRun(
    userMessage: string,
    conversationHistory: LLMMessage[] = [],
    abortSignal?: AbortSignal
  ): AsyncGenerator<StreamChunk> {
    // åˆ›å»ºæˆ–å¤ç”¨ AbortController
    if (abortSignal) {
      // ä½¿ç”¨ä¼ å…¥çš„ signal
      this.abortController = null; // å¤–éƒ¨ç®¡ç†
    } else {
      this.abortController = new AbortController();
      abortSignal = this.abortController.signal;
    }

    const llm = getLLMClient();
    const attachments: FileAttachment[] = [];
    const toolCallsExecuted: { tool: string; result: unknown }[] = [];

    // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    const messages = this.buildMessages(userMessage, conversationHistory);

    // è·å–å¯ç”¨å·¥å…·
    const tools = this.toolRegistry.listTools();

    let iterations = 0;
    let currentContent = '';

    while (true) {
      // æ£€æŸ¥ä¸­æ–­ä¿¡å·
      if (abortSignal?.aborted) {
        console.log('[OpenAICompatRunner] Execution aborted by user');
        yield { type: 'error', content: 'ç”¨æˆ·å·²åœæ­¢å¯¹è¯' };
        return;
      }

      // æ£€æŸ¥è¿­ä»£é™åˆ¶
      if (this.options.maxIterations > 0 && iterations >= this.options.maxIterations) {
        yield { type: 'complete', attachments: attachments.length > 0 ? attachments : undefined };
        return;
      }

      // è°ƒç”¨ LLM
      const toolCalls: ToolCallInfo[] = [];
      currentContent = '';

      try {
        for await (const chunk of llm.streamChat(messages, this.options.model, tools)) {
          // æ£€æŸ¥ä¸­æ–­ä¿¡å·
          if (abortSignal?.aborted) {
            console.log('[OpenAICompatRunner] Execution aborted during LLM stream');
            yield { type: 'error', content: 'ç”¨æˆ·å·²åœæ­¢å¯¹è¯' };
            return;
          }

          if (chunk.type === 'text' && chunk.content) {
            currentContent += chunk.content;
            yield { type: 'text', content: chunk.content };
          } else if (chunk.type === 'tool_call' && chunk.toolCall) {
            // è§£æå·¥å…·è°ƒç”¨å‚æ•°
            let args: Record<string, unknown> = {};
            try {
              args = JSON.parse(chunk.toolCall.arguments);
            } catch {
              args = {};
            }
            toolCalls.push({
              id: chunk.toolCall.id,
              name: chunk.toolCall.name,
              arguments: args,
            });
          }
        }
      } catch (error) {
        // å¦‚æœæ˜¯ä¸­æ–­å¯¼è‡´çš„é”™è¯¯ï¼Œè¿”å›ç‰¹å®šæ¶ˆæ¯
        if (abortSignal?.aborted) {
          console.log('[OpenAICompatRunner] LLM stream interrupted');
          yield { type: 'error', content: 'ç”¨æˆ·å·²åœæ­¢å¯¹è¯' };
          return;
        }
        const errorMessage = error instanceof Error ? error.message : String(error);
        console.error('[OpenAICompatRunner] LLM error:', errorMessage);
        yield { type: 'error', content: errorMessage };
        return;
      }

      // æ£€æŸ¥ä¸­æ–­ä¿¡å·
      if (abortSignal?.aborted) {
        yield { type: 'error', content: 'ç”¨æˆ·å·²åœæ­¢å¯¹è¯' };
        return;
      }

      // æ²¡æœ‰å·¥å…·è°ƒç”¨ï¼Œå®Œæˆ
      if (toolCalls.length === 0) {
        yield { type: 'complete', attachments: attachments.length > 0 ? attachments : undefined };
        return;
      }

      // å¤„ç†å·¥å…·è°ƒç”¨
      for (const tc of toolCalls) {
        // æ£€æŸ¥ä¸­æ–­ä¿¡å·
        if (abortSignal?.aborted) {
          yield { type: 'error', content: 'ç”¨æˆ·å·²åœæ­¢å¯¹è¯' };
          return;
        }

        const startTime = Date.now();

        console.log(`\n${'='.repeat(80)}`);
        console.log(`[OpenAICompatRunner] ğŸ”§ Tool Call Started`);
        console.log(`  Tool Name: ${tc.name}`);
        console.log(`  Tool ID: ${tc.id}`);
        console.log(`  Arguments:`, JSON.stringify(tc.arguments, null, 2));
        console.log(`${'='.repeat(80)}`);

        yield { type: 'tool_use', tool: tc.name, toolId: tc.id, args: tc.arguments };

        try {
          const result = await this.toolRegistry.execute(tc.name, tc.arguments);

          // æ£€æŸ¥ä¸­æ–­ä¿¡å·
          if (abortSignal?.aborted) {
            yield { type: 'error', content: 'ç”¨æˆ·å·²åœæ­¢å¯¹è¯' };
            return;
          }

          const duration = Date.now() - startTime;
          console.log(`\n[OpenAICompatRunner] âœ… Tool Execution Completed`);
          console.log(`  Tool: ${tc.name}`);
          console.log(`  Duration: ${duration}ms`);
          console.log(`${'='.repeat(80)}\n`);

          // æ”¶é›†é™„ä»¶
          collectAttachments(result, attachments);

          toolCallsExecuted.push({ tool: tc.name, result });

          // æ„å»ºå·¥å…·ç»“æœ
          const resultForLLM = (result && typeof result === 'object' && 'message' in result)
            ? { message: (result as Record<string, unknown>).message }
            : result;
          const resultStr = JSON.stringify(resultForLLM);
          const truncatedResult = truncateToolResult(resultStr);

          // æ·»åŠ åˆ°æ¶ˆæ¯åˆ—è¡¨
          messages.push({
            role: 'assistant',
            content: currentContent,
            tool_calls: [{ id: tc.id, name: tc.name, arguments: tc.arguments }],
          });
          messages.push({
            role: 'tool',
            toolCallId: tc.id,
            content: truncatedResult,
          });

          yield { type: 'tool_result', tool: tc.name, result: resultForLLM };
        } catch (error) {
          const duration = Date.now() - startTime;
          const errorMessage = error instanceof Error ? error.message : String(error);

          console.error(`\n[OpenAICompatRunner] âŒ Tool Execution Failed`);
          console.error(`  Tool: ${tc.name}`);
          console.error(`  Duration: ${duration}ms`);
          console.error(`  Error:`, errorMessage);
          console.error(`${'='.repeat(80)}\n`);

          messages.push({
            role: 'assistant',
            content: currentContent,
            tool_calls: [{ id: tc.id, name: tc.name, arguments: tc.arguments }],
          });
          messages.push({
            role: 'tool',
            toolCallId: tc.id,
            content: `Error: ${errorMessage}`,
          });

          yield { type: 'tool_result', tool: tc.name, result: { error: errorMessage }, isError: true };
        }
      }

      iterations++;
      // ç»§ç»­å¾ªç¯ï¼Œè®© LLM åŸºäºå·¥å…·ç»“æœç»§ç»­ç”Ÿæˆ
    }
  }

  /**
   * éæµå¼è¿è¡Œï¼ˆå…¼å®¹æ—§ APIï¼‰
   */
  async run(
    userMessage: string,
    conversationHistory: LLMMessage[] = []
  ): Promise<AgentResult> {
    let fullContent = '';
    const toolCalls: AgentResult['toolCalls'] = [];
    const attachments: FileAttachment[] = [];

    for await (const chunk of this.streamRun(userMessage, conversationHistory)) {
      if (chunk.type === 'text' && chunk.content) {
        fullContent += chunk.content;
      } else if (chunk.type === 'tool_result') {
        toolCalls.push({
          tool: chunk.tool || '',
          result: chunk.result,
        });
      } else if (chunk.type === 'complete' || chunk.type === 'error') {
        if (chunk.attachments) {
          attachments.push(...chunk.attachments);
        }
      }
    }

    return {
      response: fullContent,
      success: true,
      toolCalls,
      attachments: attachments.length > 0 ? attachments : undefined,
    };
  }

  /**
   * æ„å»ºæ¶ˆæ¯åˆ—è¡¨
   */
  private buildMessages(userMessage: string, history: LLMMessage[]): LLMMessage[] {
    const messages: LLMMessage[] = [];

    // å¦‚æœæœ‰è‡ªå®šä¹‰ç³»ç»Ÿæç¤ºè¯ï¼Œæ·»åŠ åˆ°å¼€å¤´
    if (this.options.systemPrompt) {
      messages.push({
        role: 'system',
        content: this.options.systemPrompt,
      });
    }

    // æ·»åŠ å†å²è®°å½•
    messages.push(...history);

    // æ·»åŠ ç”¨æˆ·æ¶ˆæ¯
    messages.push({
      role: 'user',
      content: userMessage,
    });

    return messages;
  }

  /**
   * ç®€å•å¯¹è¯ï¼ˆä¸å¸¦å·¥å…·ï¼‰
   */
  async simpleChat(message: string): Promise<string> {
    const llm = getLLMClient();
    return llm.simpleChat(message);
  }
}
